# Final-Year-Project-Towards-Many-to-Many-Communication-among-Blind-Deaf-Dumb-Users
<h2><b>*Note:-I have designed this project using Flask app (Mainframe API), HTML, CSS, Django to generate dynamic charts and python programming language!*</b></h2>
<h3><b> Overview </b></h3><br>
Humans are favorably quick-witted humanoids that have become the presiding classification on the Earth. The mortal’s divulgence is grounded in communal and shared
objectives. While people with hearing or visual impairments alone can find a way to share their thoughts with others and understand them, deaf blind people face a
much more difficult communication task. Thus the project accords and executes the blueprint design, paradigm and testing of a lightweight software and speaker device
with a display for the divulgence among two humanoid or also between visually impaired people.<br>

<h3><b> Existing System </b></h3><br>
In the earlier days, blind people could only read only with the help of Braille script. Braille is a type of scripting language where blind people read through the 6 
raised dots sensed by their fingers. It is traditionally written with embossed paper. Now a days Braille user can read computer screens and other electronics support
using refreshable Braille displays.<br>
On a conventional basis, the gesture sign recognition method was aggregated into two types namely vision based and sensor basemethod. In vision based method, the
input aided for this is capturing the image from the computer camera to analyze the position of the fingers. In sensor based systems, it requires having an aided
device helps in gaining the required correct finger positions and associated angles between them. The disadvantage is wearing it consistently is not feasible.<br>

<h3><b> Proposed System </b></h3><br>
The work focusses on developing “intelligent sign language recognition using image processing” which deals with the computer system in which sign language is
captured and processed and translated to speech. The proposed system makes a clear-cut view on providing a solution for the people with deafened and dumb-sighted
person to envision/ study which is in audio format by speech to text conversion process and we also provides a way for the dim-sighted person to represent their
input/ conversation by the aid of text to voice process. The implemented system empowers its utmost focus on searching a distinctive method that helps the visually
impaired in representing them with text and this system that captures or accepts uploading of the image stored directories as well and converts the text available
into corresponding correctly identified speech.<br>

<h3><b> System Design</b></h3><br>
The idea for implementing this system design is to bridge the gap between the visually impaired person & a normal person for ease of communication between them. The
proposed project is built with the most trending programming language also used in major industries ~ python. The system is provided with 4 unique and individual
modules.
<h4><b> Text to Speech </b></h4><br>
Text-to-speech technology reads aloud digital text. It can take words on computers, smartphones and convert them into audio. gTTS is the commonly used API and
accurate results are obtained. It aids in the conversion of a text entered or provided as an input by user into audio which can be saved as an mp3 file and reads it
aloud for them. The gTTS supports several languages. The speech can be delivered in the requirements for the users either slow or fast.<br>

<h4><b> Speech to Text </b></h4><br>
Speech Recognition is based on the algorithm of acoustic and language modeling. Acoustic modeling represents the relationship between speech and audio signals.
Language modeling suits resonates with term series.<br>

<h4><b> Image to Speech</b></h4><br>
Text to Speech using Camera is performed by a source called Optical Character Recognition. OCR is used to scan the image and extract the available text from the
image and perform background color and disturbances causing in the image. Thus after the final and successful recognition of the text from image it produces a sound
speech using the gTTS module. The libraries used are Pytesseract, pyttsx3, Python Imaging Library(PIL) and Googletrans.<br>

<h4><b>Hand Gesture Recognition</b></h4><br>
Existing methodology of finger tracking and outline perception for gesture sign recognition using OpenCV. Gestures play a vital role for exchange information among
the human beings. Hand gesture & sign recognition executes ample enough with the help of Machine learning methods such as neural networks, support vector machine,
and Adaptive Boosting (AdaBoost).

<h3><b>Results</b></h3><br>
<b>1. Decision Tree</b> <br>
 train results - 95.43%<br>
 test results - 93.03%<br>

2.<b>Random Forest</b><br>
  train results - 100%<br>
  test results - 99.892%<br>

3. <b>SGD Classifier</b><br>
  train results - 72.01%<br>
  test results - 73.14%<br>
  
4.<b> Long Short Term Memory</b><br>
  train results - 99.887%<br>
  test results - 98.208%<br>

5.<b> Tensor Flow Application Image Extraction</b><br>
   train results - 98.34%<br>
   test results - 98.04%<br>
